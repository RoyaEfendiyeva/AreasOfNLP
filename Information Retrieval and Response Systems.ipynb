{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Retrieval and Response Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Who created Python?\",\n",
    "\"Where is the Eiffel Tower located?\",\n",
    "\"What is the Great Wall of China?\",\n",
    "\"What is machine learning?\",\n",
    "\"What is the capital of Japan?\",\n",
    "\"What does the human brain do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')  # Plugin for Tokenizer\n",
    "\n",
    "# Database\n",
    "documents = []\n",
    "\n",
    "# Download data from file\n",
    "def load_documents_from_file(filename):\n",
    "    global documents\n",
    "    with open(filename, 'r') as file:\n",
    "        documents = file.readlines()\n",
    "\n",
    "# Stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def process_text(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "def get_dynamic_answer(question, context):\n",
    "    # Work the question\n",
    "    question_words = process_text(question)\n",
    "    \n",
    "    # Process context documents\n",
    "    context_words_list = [process_text(doc) for doc in context]\n",
    "    \n",
    "    # Match the question with each document\n",
    "    scores = []\n",
    "    for context_words in context_words_list:\n",
    "        score = sum(word in context_words for word in question_words)\n",
    "        scores.append(score)\n",
    "    \n",
    "    # Find the most suitable document\n",
    "    best_index = scores.index(max(scores))\n",
    "    return context[best_index]\n",
    "\n",
    "# Load data from file\n",
    "load_documents_from_file('C:/Users/HP/Downloads/testFileforNLP.txt')\n",
    "\n",
    "# Interaction with the user\n",
    "try:\n",
    "    while True:\n",
    "        user_question = input(\"Enter your question (type 'quit' to exit): \")\n",
    "        if user_question.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        answer = get_dynamic_answer(user_question, documents)\n",
    "        print(f\"Answer: {answer}\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nProgram terminated by user.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
